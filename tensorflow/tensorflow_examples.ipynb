{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's flow some tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple hello tensors !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # need to import the right package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant('Hello tensors!') # this is how we create tensors woith constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello tensors!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x_val = sess.run(x)\n",
    "    print(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product of M [[1 2 1]\n",
      " [2 2 2]] and V  [[1]\n",
      " [1]\n",
      " [0]] \n",
      " is [[3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "M = tf.constant([[1, 2, 1],[2, 2, 2]])\n",
    "V = tf.constant([[1], [1], [0]])\n",
    "prod = tf.matmul(M,V)\n",
    "with tf.Session() as sess:\n",
    "    prod_val, M_val, V_val = sess.run([prod, M , V])\n",
    "    print('product of M {} and V  {} \\n is {}'.format(M_val, V_val, prod_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some machine learning\n",
    "Here we will build a simple logistic regression model to classify mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify everthing looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000 training example with shape (784,)\n",
      "10000 test example with shape (784,)\n"
     ]
    }
   ],
   "source": [
    "print('{} training example with shape {}'.format(mnist.train.num_examples, mnist.train.images[0].shape))\n",
    "print('{} test example with shape {}'.format(mnist.test.num_examples, mnist.test.images[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 10\n",
    "X_DIM = 28\n",
    "Y_DIM = 28\n",
    "import numpy as np\n",
    "unique_label = np.unique(np.argmax(mnist.train.labels, 1))\n",
    "print(unique_label)\n",
    "assert NUM_CLASSES == len(unique_label), 'number of label does not match'\n",
    "assert X_DIM*Y_DIM == mnist.train.images[0].size, 'total pixel does not match'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's randomly view some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic command so that images are inline in notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt # visulaization package in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2732 43567 42613 52416]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEICAYAAAAp2fO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5AcgSiQ/AFEi+QGIEskPQJRIfgCi9P8WlbYbBZK1lAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f892b300a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0) # to make sure we have deterministic results on each iteration\n",
    "NUM_FIG_DISP = 4\n",
    "rand_ind = np.random.randint(mnist.train.num_examples, size=NUM_FIG_DISP)\n",
    "print(rand_ind)\n",
    "plt.figure(1)\n",
    "plt.gray()\n",
    "for idx, image_index in enumerate(rand_ind):\n",
    "    plt.subplot(2,2,idx +1)\n",
    "    plt.imshow(np.reshape(mnist.train.images[image_index], (X_DIM, Y_DIM)) )\n",
    "    plt.title('label is {}'.format(np.argmax(mnist.train.labels[image_index])))  \n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction vector is [None, 10]\n"
     ]
    }
   ],
   "source": [
    "PIXELS_PER_SAMPLE = X_DIM*Y_DIM\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n",
    "X =  tf.placeholder(tf.float32, [None, PIXELS_PER_SAMPLE])\n",
    "Y = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "M = tf.Variable(tf.random_normal([X_DIM*Y_DIM, NUM_CLASSES]), name='weight')\n",
    "b = tf.Variable(tf.zeros([NUM_CLASSES]), name='bias')\n",
    "Y_pred = tf.matmul(X, M) + b\n",
    "print('shape of prediction vector is {}'.format(Y_pred.get_shape().as_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert this score vector of 10 into probability vector using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_prob = tf.nn.softmax(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a loss/cost/objective function to measure how go we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-Y*tf.log(Y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build an accuracy measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.equal(tf.argmax(Y,1), tf.argmax(Y_pred_prob,1)) # picking the index of high probabiity\n",
    "accuracy = tf.cast(accuracy, tf.float32)\n",
    "accuracy = tf.reduce_mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let create an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[0].dtype)\n",
    "print(mnist.train.labels[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets run the model and see how it performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psnegi/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "epoch 1 batch 100 loss 0.319999992847 accu\n",
      "epoch 1 batch 200 loss 0.430000007153 accu\n",
      "epoch 1 batch 300 loss 0.589999973774 accu\n",
      "epoch 1 batch 400 loss 0.670000016689 accu\n",
      "epoch 1 batch 500 loss 0.709999978542 accu\n",
      "epoch 1 # test accuracy 0.647899985313#\n",
      "epoch 2 batch 100 loss 0.730000019073 accu\n",
      "epoch 2 batch 200 loss 0.660000026226 accu\n",
      "epoch 2 batch 300 loss 0.740000009537 accu\n",
      "epoch 2 batch 400 loss 0.689999997616 accu\n",
      "epoch 2 batch 500 loss 0.75 accu\n",
      "epoch 2 # test accuracy 0.747500002384#\n",
      "epoch 3 batch 100 loss 0.77999997139 accu\n",
      "epoch 3 batch 200 loss 0.850000023842 accu\n",
      "epoch 3 batch 300 loss 0.810000002384 accu\n",
      "epoch 3 batch 400 loss 0.759999990463 accu\n",
      "epoch 3 batch 500 loss 0.850000023842 accu\n",
      "epoch 3 # test accuracy 0.786400020123#\n",
      "epoch 4 batch 100 loss 0.759999990463 accu\n",
      "epoch 4 batch 200 loss 0.740000009537 accu\n",
      "epoch 4 batch 300 loss 0.77999997139 accu\n",
      "epoch 4 batch 400 loss 0.819999992847 accu\n",
      "epoch 4 batch 500 loss 0.740000009537 accu\n",
      "epoch 4 # test accuracy 0.808899998665#\n",
      "epoch 5 batch 100 loss 0.850000023842 accu\n",
      "epoch 5 batch 200 loss 0.860000014305 accu\n",
      "epoch 5 batch 300 loss 0.77999997139 accu\n",
      "epoch 5 batch 400 loss 0.829999983311 accu\n",
      "epoch 5 batch 500 loss 0.790000021458 accu\n",
      "epoch 5 # test accuracy 0.825299978256#\n",
      "epoch 6 batch 100 loss 0.829999983311 accu\n",
      "epoch 6 batch 200 loss 0.860000014305 accu\n",
      "epoch 6 batch 300 loss 0.860000014305 accu\n",
      "epoch 6 batch 400 loss 0.810000002384 accu\n",
      "epoch 6 batch 500 loss 0.790000021458 accu\n",
      "epoch 6 # test accuracy 0.83370000124#\n",
      "epoch 7 batch 100 loss 0.77999997139 accu\n",
      "epoch 7 batch 200 loss 0.810000002384 accu\n",
      "epoch 7 batch 300 loss 0.870000004768 accu\n",
      "epoch 7 batch 400 loss 0.860000014305 accu\n",
      "epoch 7 batch 500 loss 0.860000014305 accu\n",
      "epoch 7 # test accuracy 0.841300010681#\n",
      "epoch 8 batch 100 loss 0.839999973774 accu\n",
      "epoch 8 batch 200 loss 0.819999992847 accu\n",
      "epoch 8 batch 300 loss 0.870000004768 accu\n",
      "epoch 8 batch 400 loss 0.850000023842 accu\n",
      "epoch 8 batch 500 loss 0.870000004768 accu\n",
      "epoch 8 # test accuracy 0.849600017071#\n",
      "epoch 9 batch 100 loss 0.819999992847 accu\n",
      "epoch 9 batch 200 loss 0.839999973774 accu\n",
      "epoch 9 batch 300 loss 0.870000004768 accu\n",
      "epoch 9 batch 400 loss 0.790000021458 accu\n",
      "epoch 9 batch 500 loss 0.850000023842 accu\n",
      "epoch 9 # test accuracy 0.85490000248#\n",
      "epoch 10 batch 100 loss 0.889999985695 accu\n",
      "epoch 10 batch 200 loss 0.920000016689 accu\n",
      "epoch 10 batch 300 loss 0.819999992847 accu\n",
      "epoch 10 batch 400 loss 0.769999980927 accu\n",
      "epoch 10 batch 500 loss 0.839999973774 accu\n",
      "epoch 10 # test accuracy 0.858200013638#\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for eidx in range(NUM_EPOCHS):\n",
    "        for bidx in range(mnist.train.num_examples// BATCH_SIZE):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            xs = xs.astype(np.float32)\n",
    "            _, loss_val= sess.run([opt, loss], feed_dict={X:xs, Y:ys})\n",
    "            if (bidx+1)%100 == 0: # print result every 100 batch\n",
    "                accuracy_val = accuracy.eval(session=sess, feed_dict={X:xs, Y:ys})\n",
    "                print('epoch {} batch {} loss {} accu'.format(eidx +1 , bidx +1, accuracy_val))\n",
    "        print('epoch {} # test accuracy {}#'.format(eidx +1, accuracy.eval(session=sess,\n",
    "            feed_dict= {X:mnist.test.images.astype(np.float32), Y: mnist.test.labels})))        \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
