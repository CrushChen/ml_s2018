{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative model for discrete data\n",
    " - Concept learning\n",
    " - How to emulate this behavior in a machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Typical machine learning model require both positive and negative example\n",
    "- Human learning abilities(only positive examples, small sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example of concept learning. Number game Tenenbaum\n",
    "\n",
    "- Teacher Choose some arithmetic concept C e.g. prime number, multiple of 4\n",
    "- Student is given some positive example drawn at random from C in the range [1 · · · 100].\n",
    "- Student is asked whether new example xtest ∈ C \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./figures/fig3_1.pdf width=900 height=450></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=./figures/fig3_1.pdf width=900 height=450></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Empirical predictive distribution averaged over 8 humans. First, second. third and fourth row  **posterior predictive distribution $p(x|\\mathcal{D}) $ ** after seeing $\\mathcal{D} = \\{16\\}$ , $\\{60\\}$, $\\{16, 8, 2, 64\\}$ and $\\{16, 23, 19, 20\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to emulate this behavior in a machine\n",
    "## Hypothesis Space\n",
    "  Consider possible hypothesis $\\mathcal{H}$\n",
    "  - Even number\n",
    "  - odd number\n",
    "  - power of 2\n",
    "  - power of 2, plus 37\n",
    "  - power of 2 except 32\n",
    "  \n",
    "  The subset of $\\mathcal{H}$ consistent with data is called version space.\n",
    "  After seeing some example, some rule $h \\in \\mathcal{H}$ is consistent with\n",
    "  samples. How to combine them to predict $x_{test} \\in C.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## As we see more example version space shrinks\n",
    "Also in version space\n",
    " - Why we prefer one hypothesis more than other\n",
    "     + seeing D = {16, 8, 2, 64}, why did you choose the rule “powers of two” and not, say, “all even numbers”, or “powers of two except for 32”,\n",
    "     + we want to avoid suspicious coincidences between power of 2 and even number\n",
    " - how do you combine consistent rule in version space to predict if x_new ∈ C    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian explanation\n",
    "\n",
    "  - likehood function. Size principle.\n",
    "    \n",
    "    Let assume example of sampled uniformly form the extension of concept.\n",
    "    The extension of a concept is just the set of numbers that belong to it, \n",
    "    \n",
    "    Then probability of independently sampling $N$ examples from $h$ is\n",
    "    $$ p(\\mathcal{D}|h) = \\left[\\frac{1}{size(h)}\\right]^N$$\n",
    "    \n",
    "    $p(\\mathcal{D}|h_{even} ) = 1/50$, after $\\mathcal{D} =\\{16 \\}$\n",
    "    and $p(\\mathcal{D}|h_{two} ) = 1/6$, and this will increase after seeing\n",
    "    $\\mathcal{D} = {16, 8, 2, 64}$\n",
    "\n",
    "    Model favors simplest(smallest) hypothesis consistent with the data( **Occam's razer**)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Prior\n",
    "- Given D = {16, 8, 2, 64}, the concept h_1  =“powers of two except 32” is more likely than h =“powers of two”, \n",
    "- How we resolve this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Prior.\n",
    "    \n",
    "    + Intuition.\n",
    "    + Helps in bringing background knowledge to the problem.\n",
    "    + Also helps in learning from small sample size.\n",
    "     \n",
    "         Let $\\mathcal{D} = \\{16,8 , 2, 64 \\}$.\n",
    "         Given this data $p(\\mathcal{D}|h^{'} = \\text{power of two except }32)$ is more likely than $p(\\mathcal{D}|h^{'} = \\text{power of 2}),$ although unnatural.\n",
    "     \n",
    "**Which prior we should choose?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  Posterior\n",
    "<center>  \n",
    "<font   size = 8>\n",
    "  $p(h|\\mathcal{D}) = \\frac{p(\\mathcal{D}|h) p(h)}{\\sum_{h^{'} \\in \\mathcal{H}} {p(\\mathcal{D}|h^{'}) p(h^{'})} }$\n",
    "</font>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./figures/fig3_2.pdf width=900 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=./figures/fig3_2.pdf width=900 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Prior, likelihood and posterior for $\\mathcal{D} = \\{16\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./figures/fig3_3.pdf width=900 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=./figures/fig3_3.pdf width=900 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prior, likelihood and posterior for $\\mathcal{D} = \\{16, 8, 2, 64\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note the need for the low prior on the unnatural concepts\n",
    " -  would have **overfit the data** and picked “powers of 2, except for 32”.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  When we have enough data posterior become peaked on single concept, called MAP\n",
    "  (Maximum a posteriori estimatie) estimate.\n",
    "   \\begin{align}\n",
    "    \\hat(h)^{MAP}& = \\text{argmax}_h p(h|\\mathcal{D})\\\\\n",
    "    & = \\text{argmax}_h p(\\mathcal(D)|h) p(h) \\\\\n",
    "    & = \\text{argmax}_h [ \\log p(\\mathcal{D}|h) + \\log p(h)] \n",
    "    \\end{align}\n",
    "    \n",
    "   If more and more data(evidence come), eventually  $p(\\mathcal(D)|h) p(h)$\n",
    "   wins(MLE maximum likelihood estimate)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Posterior predictive distribution\n",
    "  Bayes model averaging   $p(x_{new} \\in C| \\mathcal{D}) = \\sum_h p(y =1|x_{new},h ) p(h|\\mathcal{D})$\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./figures/fig3_4.pdf width=900 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=./figures/fig3_4.pdf width=900 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Posterior over hypothesis and corresponding predictive distribution after seeing $\\mathcal{D} = \\{16\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./figures/fig3_5.pdf width=900 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=./figures/fig3_5.pdf width=900 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Predictive distribution for the model using full hypothesis space. Compare this to human experiment at the begining."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
